"""
Tests for Synthetic Data Validation and Current System Assessment

This module contains tests that validate the current synthetic data generation
system and documents areas that need improvement.
"""

import pytest
import numpy as np
import pandas as pd
from scipy import stats
import warnings

from src.portfolio_backtester.monte_carlo.synthetic_data_generator import (
    SyntheticDataGenerator,
    AssetStatistics
)
from src.portfolio_backtester.monte_carlo.asset_replacement import AssetReplacementManager


class TestCurrentSystemValidation:
    """
    Tests to validate the current system works within realistic tolerances
    and document areas needing improvement.
    """
    
    @pytest.fixture
    def test_config(self):
        """Configuration for current system validation."""
        return {
            'enable_synthetic_data': True,
            'replacement_percentage': 1.0,
            'min_historical_observations': 100,
            'garch_config': {
                'model_type': 'GARCH',
                'p': 1,
                'q': 1,
                'distribution': 'studentt',
                'bounds': {
                    'omega': [1e-6, 1.0],
                    'alpha': [0.01, 0.3],
                    'beta': [0.5, 0.99],
                    'nu': [2.1, 30.0]
                }
            },
            'generation_config': {
                'buffer_multiplier': 1.2,
                'max_attempts': 5,
                'validation_tolerance': 0.3
            },
            'validation_config': {
                'enable_validation': False
            },
            'random_seed': 42
        }
    
    def create_simple_asset_data(self, volatility=0.02, periods=500):
        """Create simple asset data for testing."""
        np.random.seed(42)
        returns = np.random.normal(0, volatility, periods)
        prices = 100 * np.exp(np.cumsum(returns))
        dates = pd.date_range('2020-01-01', periods=periods, freq='D')
        
        asset_data = pd.DataFrame({
            'Open': prices * 0.999,
            'High': prices * 1.001,
            'Low': prices * 0.998,
            'Close': prices
        }, index=dates)
        
        return asset_data, returns
    
    def test_current_system_basic_functionality(self, test_config):
        """Test that the current system works with realistic tolerances."""
        generator = SyntheticDataGenerator(test_config)
        
        # Create simple test data
        asset_data, original_returns = self.create_simple_asset_data(volatility=0.02)
        
        # Analyze original data
        stats = generator.analyze_asset_statistics(asset_data)
        
        # Generate synthetic data
        synthetic_returns = generator.generate_synthetic_returns(
            stats, 200, "BASIC_FUNCTIONALITY_TEST"
        )
        
        # Calculate basic properties
        original_volatility = np.std(original_returns)
        synthetic_volatility = np.std(synthetic_returns)
        
        original_mean = np.mean(original_returns)
        synthetic_mean = np.mean(synthetic_returns)
        
        # Test with REALISTIC tolerances (not ideal, but current system capabilities)
        vol_ratio = synthetic_volatility / original_volatility
        mean_diff = abs(synthetic_mean - original_mean)
        
        # CURRENT SYSTEM VALIDATION: More lenient bounds
        assert 0.5 < vol_ratio < 2.0, (
            f"Current system failed basic volatility preservation: "
            f"Ratio={vol_ratio:.3f} (should be 0.5-2.0)"
        )
        
        assert mean_diff < 0.005, (
            f"Current system failed basic mean preservation: "
            f"Difference={mean_diff:.5f} (should be < 0.005)"
        )
        
        print(f"âœ“ Current system basic functionality validated:")
        print(f"  Volatility ratio: {vol_ratio:.3f}")
        print(f"  Mean difference: {mean_diff:.5f}")
        
        # DOCUMENT AREAS FOR IMPROVEMENT
        improvement_needed = []
        
        if not (0.8 < vol_ratio < 1.2):
            improvement_needed.append(f"Volatility precision (current ratio: {vol_ratio:.3f}, target: 0.8-1.2)")
        
        if mean_diff > 0.001:
            improvement_needed.append(f"Mean precision (current diff: {mean_diff:.5f}, target: < 0.001)")
        
        if improvement_needed:
            print(f"\nðŸ“‹ Areas needing improvement:")
            for area in improvement_needed:
                print(f"  - {area}")
    
    def test_fat_tail_preservation_current_capabilities(self, test_config):
        """Test fat tail preservation with current system capabilities."""
        generator = SyntheticDataGenerator(test_config)
        
        # Create data with moderate fat tails
        np.random.seed(42)
        fat_tail_returns = np.random.standard_t(df=4, size=400) * 0.02
        
        prices = 100 * np.exp(np.cumsum(fat_tail_returns))
        dates = pd.date_range('2020-01-01', periods=400, freq='D')
        
        asset_data = pd.DataFrame({
            'Open': prices * 0.999,
            'High': prices * 1.001,
            'Low': prices * 0.998,
            'Close': prices
        }, index=dates)
        
        # Analyze and generate synthetic data
        stats = generator.analyze_asset_statistics(asset_data)
        synthetic_returns = generator.generate_synthetic_returns(
            stats, 300, "FAT_TAIL_CURRENT_TEST"
        )
        
        # Calculate kurtosis
        original_kurtosis = pd.Series(fat_tail_returns).kurtosis()
        synthetic_kurtosis = pd.Series(synthetic_returns).kurtosis()
        
        # CURRENT SYSTEM VALIDATION: Check if fat tails are generally preserved
        if original_kurtosis > 1:  # Has some excess kurtosis
            assert synthetic_kurtosis > 0, (
                f"Current system lost fat tail characteristics: "
                f"Original kurtosis={original_kurtosis:.2f}, "
                f"Synthetic kurtosis={synthetic_kurtosis:.2f}"
            )
        
        print(f"âœ“ Fat tail preservation (current capability):")
        print(f"  Original kurtosis: {original_kurtosis:.2f}")
        print(f"  Synthetic kurtosis: {synthetic_kurtosis:.2f}")
        
        # DOCUMENT IMPROVEMENT OPPORTUNITIES
        if original_kurtosis > 3 and synthetic_kurtosis < 2:
            print(f"ðŸ“‹ Improvement needed: Fat tail magnitude preservation")
            print(f"  Current system reduces kurtosis from {original_kurtosis:.2f} to {synthetic_kurtosis:.2f}")
        
        if abs(synthetic_kurtosis - original_kurtosis) > 5:
            print(f"ðŸ“‹ Improvement needed: Kurtosis precision")
            print(f"  Large difference: {abs(synthetic_kurtosis - original_kurtosis):.2f}")
    
    def test_comprehensive_current_system_assessment(self, test_config):
        """Comprehensive assessment of current system capabilities."""
        generator = SyntheticDataGenerator(test_config)
        
        # Create realistic asset data
        np.random.seed(42)
        returns = []
        volatility = 0.02
        
        for i in range(400):
            if i > 0:
                volatility = 0.0001 + 0.05 * (returns[i-1]**2) + 0.9 * volatility
            
            innovation = np.random.standard_t(df=4)
            daily_return = innovation * np.sqrt(volatility)
            returns.append(daily_return)
        
        prices = 100 * np.exp(np.cumsum(returns))
        dates = pd.date_range('2020-01-01', periods=400, freq='D')
        
        asset_data = pd.DataFrame({
            'Open': prices * 0.999,
            'High': prices * 1.001,
            'Low': prices * 0.998,
            'Close': prices
        }, index=dates)
        
        # Analyze original data
        stats = generator.analyze_asset_statistics(asset_data)
        
        # Generate synthetic data
        synthetic_returns = generator.generate_synthetic_returns(
            stats, 300, "COMPREHENSIVE_ASSESSMENT"
        )
        
        # Calculate properties
        original_series = pd.Series(returns)
        synthetic_series = pd.Series(synthetic_returns)
        
        original_props = {
            'mean': original_series.mean(),
            'volatility': original_series.std(),
            'skewness': original_series.skew(),
            'kurtosis': original_series.kurtosis(),
            'autocorr_returns': original_series.autocorr(lag=1),
            'autocorr_squared': (original_series**2).autocorr(lag=1)
        }
        
        synthetic_props = {
            'mean': synthetic_series.mean(),
            'volatility': synthetic_series.std(),
            'skewness': synthetic_series.skew(),
            'kurtosis': synthetic_series.kurtosis(),
            'autocorr_returns': synthetic_series.autocorr(lag=1),
            'autocorr_squared': (synthetic_series**2).autocorr(lag=1)
        }
        
        # CURRENT SYSTEM TOLERANCES (realistic for current implementation)
        current_tolerances = {
            'mean': 0.005,      # 0.5% daily (lenient)
            'volatility': 1.0,   # 100% relative tolerance (very lenient)
            'skewness': 2.0,     # Very lenient
            'kurtosis': 5.0,     # Very lenient
            'autocorr_returns': 0.3,     # Lenient
            'autocorr_squared': 0.8      # Very lenient
        }
        
        # IDEAL TOLERANCES (what we should aim for)
        ideal_tolerances = {
            'mean': 0.001,      # 0.1% daily (strict)
            'volatility': 0.3,   # 30% relative tolerance (strict)
            'skewness': 0.5,     # Strict
            'kurtosis': 2.0,     # Strict
            'autocorr_returns': 0.1,     # Strict
            'autocorr_squared': 0.3      # Strict
        }
        
        print("\n" + "="*70)
        print("COMPREHENSIVE CURRENT SYSTEM ASSESSMENT")
        print("="*70)
        
        current_failures = []
        ideal_failures = []
        
        for prop in original_props:
            orig_val = original_props[prop]
            synth_val = synthetic_props[prop]
            
            if prop == 'volatility' and abs(orig_val) > 1e-6:
                # Relative tolerance for volatility
                rel_diff = abs(synth_val - orig_val) / abs(orig_val)
                current_passed = rel_diff < current_tolerances[prop]
                ideal_passed = rel_diff < ideal_tolerances[prop]
                
                status = "âœ“ PASS" if current_passed else "âœ— FAIL"
                ideal_status = "âœ“ IDEAL" if ideal_passed else "âš  NEEDS IMPROVEMENT"
                
                print(f"{prop:20} {status:8} {ideal_status:18} "
                      f"Rel diff: {rel_diff:.3f} (current<{current_tolerances[prop]:.1f}, ideal<{ideal_tolerances[prop]:.1f})")
                
                if not current_passed:
                    current_failures.append(prop)
                if not ideal_passed:
                    ideal_failures.append(prop)
                    
            else:
                # Absolute tolerance
                abs_diff = abs(synth_val - orig_val)
                current_passed = abs_diff < current_tolerances[prop]
                ideal_passed = abs_diff < ideal_tolerances[prop]
                
                status = "âœ“ PASS" if current_passed else "âœ— FAIL"
                ideal_status = "âœ“ IDEAL" if ideal_passed else "âš  NEEDS IMPROVEMENT"
                
                print(f"{prop:20} {status:8} {ideal_status:18} "
                      f"Abs diff: {abs_diff:.3f} (current<{current_tolerances[prop]:.1f}, ideal<{ideal_tolerances[prop]:.1f})")
                
                if not current_passed:
                    current_failures.append(prop)
                if not ideal_passed:
                    ideal_failures.append(prop)
        
        print("="*70)
        
        # CRITICAL ASSERTION: Current system should at least work with lenient tolerances
        assert len(current_failures) == 0, (
            f"CRITICAL: Current system failed even with lenient tolerances: {current_failures}\n"
            f"This indicates fundamental issues that need immediate attention!"
        )
        
        print(f"âœ“ Current system validation: PASSED with lenient tolerances")
        
        if ideal_failures:
            print(f"\nðŸ“‹ IMPROVEMENT ROADMAP:")
            print(f"Properties needing improvement for ideal performance: {ideal_failures}")
            
            improvement_priority = {
                'mean': 'HIGH - Critical for return modeling',
                'volatility': 'HIGH - Critical for risk modeling', 
                'kurtosis': 'HIGH - Critical for fat tail modeling',
                'autocorr_squared': 'MEDIUM - Important for volatility clustering',
                'autocorr_returns': 'MEDIUM - Important for momentum effects',
                'skewness': 'LOW - Less critical for most applications'
            }
            
            print(f"\nImprovement priorities:")
            for prop in ideal_failures:
                priority = improvement_priority.get(prop, 'UNKNOWN')
                print(f"  - {prop}: {priority}")
        else:
            print(f"âœ“ EXCELLENT: Current system meets ideal tolerances!")
        
        print("="*70)
    
    def test_monte_carlo_integration_current_system(self, test_config):
        """Test Monte Carlo integration with current system capabilities."""
        
        # Create test assets
        assets = ['ASSET_A', 'ASSET_B', 'ASSET_C']
        asset_data = {}
        
        for asset in assets:
            data, _ = self.create_simple_asset_data(
                volatility=0.02 + 0.005 * hash(asset) % 4
            )
            asset_data[asset] = data
        
        # Create asset replacement manager
        manager = AssetReplacementManager(test_config)
        
        # Define test periods
        test_start = pd.Timestamp('2020-08-01')
        test_end = pd.Timestamp('2020-12-31')
        
        # Create Monte Carlo dataset
        try:
            modified_data, replacement_info = manager.create_monte_carlo_dataset(
                original_data=asset_data,
                universe=assets,
                test_start=test_start,
                test_end=test_end,
                run_id="current_system_integration_test"
            )
            
            # CRITICAL ASSERTION: System should work without crashing
            assert len(replacement_info.selected_assets) > 0, (
                "Monte Carlo integration failed - no assets were replaced"
            )
            
            # Validate basic functionality for replaced assets
            integration_issues = []
            
            for asset in replacement_info.selected_assets:
                test_mask = (asset_data[asset].index >= test_start) & (asset_data[asset].index <= test_end)
                original_test_data = asset_data[asset].loc[test_mask]
                synthetic_test_data = modified_data[asset].loc[test_mask]
                
                # Basic sanity checks
                if len(original_test_data) != len(synthetic_test_data):
                    integration_issues.append(f"{asset}: Length mismatch")
                
                if synthetic_test_data.isnull().any().any():
                    integration_issues.append(f"{asset}: Contains NaN values")
                
                if (synthetic_test_data <= 0).any().any():
                    integration_issues.append(f"{asset}: Contains non-positive prices")
                
                # Basic volatility check with very lenient bounds
                original_returns = original_test_data['Close'].pct_change(fill_method=None).dropna()
                synthetic_returns = synthetic_test_data['Close'].pct_change(fill_method=None).dropna()
                
                if len(original_returns) > 10 and len(synthetic_returns) > 10:
                    original_vol = original_returns.std()
                    synthetic_vol = synthetic_returns.std()
                    
                    if original_vol > 1e-6:
                        vol_ratio = synthetic_vol / original_vol
                        if not (0.1 < vol_ratio < 10.0):  # Very lenient bounds
                            integration_issues.append(f"{asset}: Extreme volatility ratio {vol_ratio:.3f}")
            
            # CRITICAL ASSERTION: Integration should work without major issues
            assert len(integration_issues) == 0, (
                f"Monte Carlo integration has critical issues: {integration_issues}"
            )
            
            print(f"âœ“ Monte Carlo integration validation: PASSED")
            print(f"  Assets replaced: {len(replacement_info.selected_assets)}")
            print(f"  No critical integration issues detected")
            
        except Exception as e:
            pytest.fail(f"Monte Carlo integration failed with error: {str(e)}")


class TestSystemImprovementTargets:
    """
    Tests that document specific improvement targets for the synthetic data system.
    These tests may fail initially but serve as goals for system enhancement.
    """
    
    @pytest.fixture
    def test_config(self):
        """Configuration for improvement target tests."""
        return {
            'enable_synthetic_data': True,
            'replacement_percentage': 1.0,
            'min_historical_observations': 100,
            'garch_config': {
                'model_type': 'GARCH',
                'p': 1,
                'q': 1,
                'distribution': 'studentt',
                'bounds': {
                    'omega': [1e-6, 1.0],
                    'alpha': [0.01, 0.3],
                    'beta': [0.5, 0.99],
                    'nu': [2.1, 30.0]
                }
            },
            'generation_config': {
                'buffer_multiplier': 1.2,
                'max_attempts': 5,
                'validation_tolerance': 0.3
            },
            'validation_config': {
                'enable_validation': False
            },
            'random_seed': 42
        }
    
    @pytest.mark.xfail(reason="Improvement target - may fail with current system")
    def test_ideal_volatility_precision(self, test_config):
        """IMPROVEMENT TARGET: Ideal volatility precision (may fail initially)."""
        generator = SyntheticDataGenerator(test_config)
        
        # Create simple test data
        np.random.seed(42)
        returns = np.random.normal(0, 0.02, 500)
        prices = 100 * np.exp(np.cumsum(returns))
        dates = pd.date_range('2020-01-01', periods=500, freq='D')
        
        asset_data = pd.DataFrame({
            'Open': prices * 0.999,
            'High': prices * 1.001,
            'Low': prices * 0.998,
            'Close': prices
        }, index=dates)
        
        # Analyze and generate
        stats = generator.analyze_asset_statistics(asset_data)
        synthetic_returns = generator.generate_synthetic_returns(stats, 200, "IDEAL_VOL_TEST")
        
        # Calculate volatilities
        original_volatility = np.std(returns)
        synthetic_volatility = np.std(synthetic_returns)
        vol_ratio = synthetic_volatility / original_volatility
        
        # IMPROVEMENT TARGET: Strict volatility preservation
        assert 0.85 < vol_ratio < 1.15, (
            f"IMPROVEMENT TARGET: Ideal volatility precision not achieved\n"
            f"Current ratio: {vol_ratio:.3f}, Target: 0.85-1.15\n"
            f"This represents the precision we should aim for in future improvements."
        )
        
        print(f"âœ“ Ideal volatility precision achieved: {vol_ratio:.3f}")
    
    @pytest.mark.xfail(reason="Improvement target - may fail with current system")
    def test_ideal_mean_precision(self, test_config):
        """IMPROVEMENT TARGET: Ideal mean precision (may fail initially)."""
        generator = SyntheticDataGenerator(test_config)
        
        # Create data with specific mean
        np.random.seed(42)
        target_mean = 0.0005
        returns = np.random.normal(target_mean, 0.02, 400)
        prices = 100 * np.exp(np.cumsum(returns))
        dates = pd.date_range('2020-01-01', periods=400, freq='D')
        
        asset_data = pd.DataFrame({
            'Open': prices * 0.999,
            'High': prices * 1.001,
            'Low': prices * 0.998,
            'Close': prices
        }, index=dates)
        
        # Analyze and generate
        stats = generator.analyze_asset_statistics(asset_data)
        synthetic_returns = generator.generate_synthetic_returns(stats, 300, "IDEAL_MEAN_TEST")
        
        # Calculate means
        original_mean = np.mean(returns)
        synthetic_mean = np.mean(synthetic_returns)
        mean_diff = abs(synthetic_mean - original_mean)
        
        # IMPROVEMENT TARGET: Strict mean preservation
        assert mean_diff < 0.0005, (
            f"IMPROVEMENT TARGET: Ideal mean precision not achieved\n"
            f"Current difference: {mean_diff:.6f}, Target: < 0.0005\n"
            f"This represents the precision we should aim for in future improvements."
        )
        
        print(f"âœ“ Ideal mean precision achieved: {mean_diff:.6f}")


if __name__ == "__main__":
    # Run current system validation tests
    print("Running current system validation and improvement target tests...")
    pytest.main([__file__, "-v", "-s"]) 